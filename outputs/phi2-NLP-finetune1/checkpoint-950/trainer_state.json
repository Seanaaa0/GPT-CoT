{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 7.983193277310924,
  "eval_steps": 500,
  "global_step": 950,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08403361344537816,
      "grad_norm": 0.17659656703472137,
      "learning_rate": 7.142857142857143e-05,
      "loss": 0.4645,
      "step": 10
    },
    {
      "epoch": 0.16806722689075632,
      "grad_norm": 0.35140281915664673,
      "learning_rate": 0.00014285714285714287,
      "loss": 0.3857,
      "step": 20
    },
    {
      "epoch": 0.25210084033613445,
      "grad_norm": 0.37973400950431824,
      "learning_rate": 0.00019999768801972172,
      "loss": 0.1804,
      "step": 30
    },
    {
      "epoch": 0.33613445378151263,
      "grad_norm": 0.2586178481578827,
      "learning_rate": 0.0001999167799344583,
      "loss": 0.033,
      "step": 40
    },
    {
      "epoch": 0.42016806722689076,
      "grad_norm": 0.030617060139775276,
      "learning_rate": 0.00019972037971811802,
      "loss": 0.0093,
      "step": 50
    },
    {
      "epoch": 0.5042016806722689,
      "grad_norm": 0.12314868718385696,
      "learning_rate": 0.00019940871438641882,
      "loss": 0.0058,
      "step": 60
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 0.16765961050987244,
      "learning_rate": 0.0001989821441880933,
      "loss": 0.0041,
      "step": 70
    },
    {
      "epoch": 0.6722689075630253,
      "grad_norm": 0.029591958969831467,
      "learning_rate": 0.00019844116218848334,
      "loss": 0.0027,
      "step": 80
    },
    {
      "epoch": 0.7563025210084033,
      "grad_norm": 0.05907541513442993,
      "learning_rate": 0.00019778639369961415,
      "loss": 0.0019,
      "step": 90
    },
    {
      "epoch": 0.8403361344537815,
      "grad_norm": 0.06282562017440796,
      "learning_rate": 0.00019701859555740648,
      "loss": 0.0015,
      "step": 100
    },
    {
      "epoch": 0.9243697478991597,
      "grad_norm": 0.03519593924283981,
      "learning_rate": 0.0001961386552468627,
      "loss": 0.0015,
      "step": 110
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.00034137084730900824,
      "eval_runtime": 23.14,
      "eval_samples_per_second": 2.161,
      "eval_steps_per_second": 0.562,
      "step": 119
    },
    {
      "epoch": 1.0084033613445378,
      "grad_norm": 0.04934791475534439,
      "learning_rate": 0.00019514758987623784,
      "loss": 0.0012,
      "step": 120
    },
    {
      "epoch": 1.092436974789916,
      "grad_norm": 0.050452034920454025,
      "learning_rate": 0.00019404654500138117,
      "loss": 0.001,
      "step": 130
    },
    {
      "epoch": 1.1764705882352942,
      "grad_norm": 0.035614240914583206,
      "learning_rate": 0.00019283679330160726,
      "loss": 0.0012,
      "step": 140
    },
    {
      "epoch": 1.2605042016806722,
      "grad_norm": 0.04908411577343941,
      "learning_rate": 0.00019151973310862754,
      "loss": 0.0011,
      "step": 150
    },
    {
      "epoch": 1.3445378151260505,
      "grad_norm": 0.0841565802693367,
      "learning_rate": 0.0001900968867902419,
      "loss": 0.003,
      "step": 160
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 0.03554442897439003,
      "learning_rate": 0.00018856989899065942,
      "loss": 0.0011,
      "step": 170
    },
    {
      "epoch": 1.5126050420168067,
      "grad_norm": 0.03574007749557495,
      "learning_rate": 0.00018694053472948156,
      "loss": 0.0009,
      "step": 180
    },
    {
      "epoch": 1.596638655462185,
      "grad_norm": 0.0022430098615586758,
      "learning_rate": 0.00018521067736154568,
      "loss": 0.0018,
      "step": 190
    },
    {
      "epoch": 1.680672268907563,
      "grad_norm": 0.008194753900170326,
      "learning_rate": 0.0001833823263999867,
      "loss": 0.0008,
      "step": 200
    },
    {
      "epoch": 1.7647058823529411,
      "grad_norm": 0.14640720188617706,
      "learning_rate": 0.00018145759520503358,
      "loss": 0.001,
      "step": 210
    },
    {
      "epoch": 1.8487394957983194,
      "grad_norm": 0.024561872705817223,
      "learning_rate": 0.00017943870854121124,
      "loss": 0.0007,
      "step": 220
    },
    {
      "epoch": 1.9327731092436975,
      "grad_norm": 0.007362126838415861,
      "learning_rate": 0.00017732800000577303,
      "loss": 0.0009,
      "step": 230
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.0005842397222295403,
      "eval_runtime": 22.7049,
      "eval_samples_per_second": 2.202,
      "eval_steps_per_second": 0.573,
      "step": 238
    },
    {
      "epoch": 2.0168067226890756,
      "grad_norm": 0.030178885906934738,
      "learning_rate": 0.00017512790933133437,
      "loss": 0.0009,
      "step": 240
    },
    {
      "epoch": 2.100840336134454,
      "grad_norm": 0.07778486609458923,
      "learning_rate": 0.00017284097956582692,
      "loss": 0.0008,
      "step": 250
    },
    {
      "epoch": 2.184873949579832,
      "grad_norm": 0.019527392461895943,
      "learning_rate": 0.00017046985413303215,
      "loss": 0.0007,
      "step": 260
    },
    {
      "epoch": 2.26890756302521,
      "grad_norm": 0.005586286541074514,
      "learning_rate": 0.00016801727377709194,
      "loss": 0.0008,
      "step": 270
    },
    {
      "epoch": 2.3529411764705883,
      "grad_norm": 0.010222874581813812,
      "learning_rate": 0.00016548607339452853,
      "loss": 0.0007,
      "step": 280
    },
    {
      "epoch": 2.4369747899159666,
      "grad_norm": 0.021889174357056618,
      "learning_rate": 0.00016287917875743496,
      "loss": 0.0009,
      "step": 290
    },
    {
      "epoch": 2.5210084033613445,
      "grad_norm": 0.04718570411205292,
      "learning_rate": 0.00016019960313162434,
      "loss": 0.0003,
      "step": 300
    },
    {
      "epoch": 2.6050420168067228,
      "grad_norm": 0.05351473018527031,
      "learning_rate": 0.00015745044379364634,
      "loss": 0.0005,
      "step": 310
    },
    {
      "epoch": 2.689075630252101,
      "grad_norm": 0.001976537052541971,
      "learning_rate": 0.00015463487845069707,
      "loss": 0.0006,
      "step": 320
    },
    {
      "epoch": 2.773109243697479,
      "grad_norm": 0.012275313958525658,
      "learning_rate": 0.00015175616156756072,
      "loss": 0.0004,
      "step": 330
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 0.029521679505705833,
      "learning_rate": 0.00014881762060482814,
      "loss": 0.0007,
      "step": 340
    },
    {
      "epoch": 2.9411764705882355,
      "grad_norm": 0.021649515256285667,
      "learning_rate": 0.00014582265217274104,
      "loss": 0.0012,
      "step": 350
    },
    {
      "epoch": 3.0,
      "eval_loss": 8.518384856870398e-05,
      "eval_runtime": 22.7678,
      "eval_samples_per_second": 2.196,
      "eval_steps_per_second": 0.571,
      "step": 357
    },
    {
      "epoch": 3.0252100840336134,
      "grad_norm": 0.04240604490041733,
      "learning_rate": 0.0001427747181051071,
      "loss": 0.0005,
      "step": 360
    },
    {
      "epoch": 3.1092436974789917,
      "grad_norm": 0.05488879233598709,
      "learning_rate": 0.00013967734145782425,
      "loss": 0.0004,
      "step": 370
    },
    {
      "epoch": 3.19327731092437,
      "grad_norm": 0.005470279138535261,
      "learning_rate": 0.00013653410243663952,
      "loss": 0.0009,
      "step": 380
    },
    {
      "epoch": 3.277310924369748,
      "grad_norm": 0.0014887750148773193,
      "learning_rate": 0.00013334863425884907,
      "loss": 0.0001,
      "step": 390
    },
    {
      "epoch": 3.361344537815126,
      "grad_norm": 0.0030332724563777447,
      "learning_rate": 0.00013012461895372344,
      "loss": 0.0005,
      "step": 400
    },
    {
      "epoch": 3.4453781512605044,
      "grad_norm": 0.06816916167736053,
      "learning_rate": 0.0001268657831065114,
      "loss": 0.0006,
      "step": 410
    },
    {
      "epoch": 3.5294117647058822,
      "grad_norm": 0.015499352477490902,
      "learning_rate": 0.00012357589355094275,
      "loss": 0.0001,
      "step": 420
    },
    {
      "epoch": 3.6134453781512605,
      "grad_norm": 0.0016568199498578906,
      "learning_rate": 0.0001202587530152081,
      "loss": 0.0002,
      "step": 430
    },
    {
      "epoch": 3.697478991596639,
      "grad_norm": 0.006442970130592585,
      "learning_rate": 0.00011691819572644939,
      "loss": 0.0001,
      "step": 440
    },
    {
      "epoch": 3.7815126050420167,
      "grad_norm": 0.0038217396941035986,
      "learning_rate": 0.00011355808297884078,
      "loss": 0.0002,
      "step": 450
    },
    {
      "epoch": 3.865546218487395,
      "grad_norm": 0.0008141410653479397,
      "learning_rate": 0.00011018229867038356,
      "loss": 0.0003,
      "step": 460
    },
    {
      "epoch": 3.9495798319327733,
      "grad_norm": 0.0012742850231006742,
      "learning_rate": 0.00010679474481357341,
      "loss": 0.0002,
      "step": 470
    },
    {
      "epoch": 4.0,
      "eval_loss": 0.00018857441318687052,
      "eval_runtime": 22.7491,
      "eval_samples_per_second": 2.198,
      "eval_steps_per_second": 0.571,
      "step": 476
    },
    {
      "epoch": 4.033613445378151,
      "grad_norm": 0.008155196905136108,
      "learning_rate": 0.00010339933702512979,
      "loss": 0.0009,
      "step": 480
    },
    {
      "epoch": 4.117647058823529,
      "grad_norm": 0.0008738429751247168,
      "learning_rate": 0.0001,
      "loss": 0.0002,
      "step": 490
    },
    {
      "epoch": 4.201680672268908,
      "grad_norm": 0.014961701817810535,
      "learning_rate": 9.660066297487022e-05,
      "loss": 0.0001,
      "step": 500
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 0.0018995699938386679,
      "learning_rate": 9.320525518642661e-05,
      "loss": 0.0001,
      "step": 510
    },
    {
      "epoch": 4.369747899159664,
      "grad_norm": 0.00148024782538414,
      "learning_rate": 8.981770132961649e-05,
      "loss": 0.0001,
      "step": 520
    },
    {
      "epoch": 4.453781512605042,
      "grad_norm": 0.026714880019426346,
      "learning_rate": 8.644191702115924e-05,
      "loss": 0.0001,
      "step": 530
    },
    {
      "epoch": 4.53781512605042,
      "grad_norm": 0.001839907607063651,
      "learning_rate": 8.308180427355062e-05,
      "loss": 0.0002,
      "step": 540
    },
    {
      "epoch": 4.621848739495798,
      "grad_norm": 0.015146304853260517,
      "learning_rate": 7.974124698479192e-05,
      "loss": 0.0002,
      "step": 550
    },
    {
      "epoch": 4.705882352941177,
      "grad_norm": 0.014600444585084915,
      "learning_rate": 7.642410644905726e-05,
      "loss": 0.0005,
      "step": 560
    },
    {
      "epoch": 4.7899159663865545,
      "grad_norm": 0.012722472660243511,
      "learning_rate": 7.313421689348862e-05,
      "loss": 0.0001,
      "step": 570
    },
    {
      "epoch": 4.873949579831933,
      "grad_norm": 0.0007656721863895655,
      "learning_rate": 6.98753810462766e-05,
      "loss": 0.0001,
      "step": 580
    },
    {
      "epoch": 4.957983193277311,
      "grad_norm": 0.004364549182355404,
      "learning_rate": 6.665136574115096e-05,
      "loss": 0.0001,
      "step": 590
    },
    {
      "epoch": 5.0,
      "eval_loss": 1.5751600585645065e-05,
      "eval_runtime": 22.9035,
      "eval_samples_per_second": 2.183,
      "eval_steps_per_second": 0.568,
      "step": 595
    },
    {
      "epoch": 5.042016806722689,
      "grad_norm": 0.0008055933867581189,
      "learning_rate": 6.34658975633605e-05,
      "loss": 0.0006,
      "step": 600
    },
    {
      "epoch": 5.126050420168067,
      "grad_norm": 0.0014354977756738663,
      "learning_rate": 6.0322658542175736e-05,
      "loss": 0.0002,
      "step": 610
    },
    {
      "epoch": 5.2100840336134455,
      "grad_norm": 0.01566050574183464,
      "learning_rate": 5.7225281894892935e-05,
      "loss": 0.0001,
      "step": 620
    },
    {
      "epoch": 5.294117647058823,
      "grad_norm": 0.000781396753154695,
      "learning_rate": 5.417734782725896e-05,
      "loss": 0.0003,
      "step": 630
    },
    {
      "epoch": 5.378151260504202,
      "grad_norm": 0.038332752883434296,
      "learning_rate": 5.11823793951719e-05,
      "loss": 0.0002,
      "step": 640
    },
    {
      "epoch": 5.46218487394958,
      "grad_norm": 0.016284413635730743,
      "learning_rate": 4.824383843243929e-05,
      "loss": 0.0003,
      "step": 650
    },
    {
      "epoch": 5.546218487394958,
      "grad_norm": 0.0008829063735902309,
      "learning_rate": 4.5365121549302914e-05,
      "loss": 0.0001,
      "step": 660
    },
    {
      "epoch": 5.630252100840336,
      "grad_norm": 0.008331646211445332,
      "learning_rate": 4.25495562063537e-05,
      "loss": 0.0003,
      "step": 670
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 0.0034193352330476046,
      "learning_rate": 3.980039686837568e-05,
      "loss": 0.0,
      "step": 680
    },
    {
      "epoch": 5.798319327731092,
      "grad_norm": 0.000571447832044214,
      "learning_rate": 3.7120821242565086e-05,
      "loss": 0.0001,
      "step": 690
    },
    {
      "epoch": 5.882352941176471,
      "grad_norm": 0.0013066197279840708,
      "learning_rate": 3.45139266054715e-05,
      "loss": 0.0001,
      "step": 700
    },
    {
      "epoch": 5.966386554621849,
      "grad_norm": 0.00386405480094254,
      "learning_rate": 3.198272622290804e-05,
      "loss": 0.0001,
      "step": 710
    },
    {
      "epoch": 6.0,
      "eval_loss": 1.3693340406462085e-05,
      "eval_runtime": 23.1849,
      "eval_samples_per_second": 2.157,
      "eval_steps_per_second": 0.561,
      "step": 714
    },
    {
      "epoch": 6.050420168067227,
      "grad_norm": 0.006010985001921654,
      "learning_rate": 2.9530145866967895e-05,
      "loss": 0.0001,
      "step": 720
    },
    {
      "epoch": 6.1344537815126055,
      "grad_norm": 0.0007902429206296802,
      "learning_rate": 2.71590204341731e-05,
      "loss": 0.0003,
      "step": 730
    },
    {
      "epoch": 6.218487394957983,
      "grad_norm": 0.001909685437567532,
      "learning_rate": 2.487209066866565e-05,
      "loss": 0.0001,
      "step": 740
    },
    {
      "epoch": 6.302521008403361,
      "grad_norm": 0.0006505398196168244,
      "learning_rate": 2.2671999994226978e-05,
      "loss": 0.0001,
      "step": 750
    },
    {
      "epoch": 6.38655462184874,
      "grad_norm": 0.0016274615190923214,
      "learning_rate": 2.0561291458788733e-05,
      "loss": 0.0,
      "step": 760
    },
    {
      "epoch": 6.470588235294118,
      "grad_norm": 0.002923065098002553,
      "learning_rate": 1.854240479496643e-05,
      "loss": 0.0001,
      "step": 770
    },
    {
      "epoch": 6.554621848739496,
      "grad_norm": 0.0007558417273685336,
      "learning_rate": 1.6617673600013296e-05,
      "loss": 0.0001,
      "step": 780
    },
    {
      "epoch": 6.6386554621848735,
      "grad_norm": 0.0013045466039329767,
      "learning_rate": 1.4789322638454351e-05,
      "loss": 0.0002,
      "step": 790
    },
    {
      "epoch": 6.722689075630252,
      "grad_norm": 0.005680948030203581,
      "learning_rate": 1.3059465270518468e-05,
      "loss": 0.0001,
      "step": 800
    },
    {
      "epoch": 6.80672268907563,
      "grad_norm": 0.0040878173895180225,
      "learning_rate": 1.1430101009340576e-05,
      "loss": 0.0002,
      "step": 810
    },
    {
      "epoch": 6.890756302521009,
      "grad_norm": 0.0009618984186090529,
      "learning_rate": 9.903113209758096e-06,
      "loss": 0.0,
      "step": 820
    },
    {
      "epoch": 6.974789915966387,
      "grad_norm": 0.028840718790888786,
      "learning_rate": 8.480266891372469e-06,
      "loss": 0.0001,
      "step": 830
    },
    {
      "epoch": 7.0,
      "eval_loss": 1.2150117981946096e-05,
      "eval_runtime": 19.59,
      "eval_samples_per_second": 2.552,
      "eval_steps_per_second": 0.664,
      "step": 833
    },
    {
      "epoch": 7.0588235294117645,
      "grad_norm": 0.0009308746666647494,
      "learning_rate": 7.163206698392744e-06,
      "loss": 0.0001,
      "step": 840
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.0009257878991775215,
      "learning_rate": 5.953454998618857e-06,
      "loss": 0.0002,
      "step": 850
    },
    {
      "epoch": 7.226890756302521,
      "grad_norm": 0.0036035049706697464,
      "learning_rate": 4.8524101237621635e-06,
      "loss": 0.0,
      "step": 860
    },
    {
      "epoch": 7.310924369747899,
      "grad_norm": 0.0013631317997351289,
      "learning_rate": 3.861344753137319e-06,
      "loss": 0.0001,
      "step": 870
    },
    {
      "epoch": 7.394957983193278,
      "grad_norm": 0.004112372174859047,
      "learning_rate": 2.9814044425935606e-06,
      "loss": 0.0001,
      "step": 880
    },
    {
      "epoch": 7.4789915966386555,
      "grad_norm": 0.0006786928861401975,
      "learning_rate": 2.2136063003858733e-06,
      "loss": 0.0,
      "step": 890
    },
    {
      "epoch": 7.563025210084033,
      "grad_norm": 0.0016268015606328845,
      "learning_rate": 1.5588378115166669e-06,
      "loss": 0.0001,
      "step": 900
    },
    {
      "epoch": 7.647058823529412,
      "grad_norm": 0.001457704114727676,
      "learning_rate": 1.0178558119067315e-06,
      "loss": 0.0001,
      "step": 910
    },
    {
      "epoch": 7.73109243697479,
      "grad_norm": 0.0028628085274249315,
      "learning_rate": 5.912856135812051e-07,
      "loss": 0.0001,
      "step": 920
    },
    {
      "epoch": 7.815126050420168,
      "grad_norm": 0.0009037464624270797,
      "learning_rate": 2.7962028188198706e-07,
      "loss": 0.0001,
      "step": 930
    },
    {
      "epoch": 7.899159663865547,
      "grad_norm": 0.002714043017476797,
      "learning_rate": 8.322006554171146e-08,
      "loss": 0.0001,
      "step": 940
    },
    {
      "epoch": 7.983193277310924,
      "grad_norm": 0.0009781700791791081,
      "learning_rate": 2.3119802783022615e-09,
      "loss": 0.0001,
      "step": 950
    }
  ],
  "logging_steps": 10,
  "max_steps": 952,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6.178484939390976e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
