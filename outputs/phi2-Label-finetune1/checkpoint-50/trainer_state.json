{
  "best_metric": 0.009738137014210224,
  "best_model_checkpoint": "/home/seana/axolotl_project/outputs/phi2-Label-finetune1/checkpoint-20",
  "epoch": 0.6993006993006993,
  "eval_steps": 10,
  "global_step": 50,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013986013986013986,
      "eval_loss": 0.37026792764663696,
      "eval_runtime": 12.0544,
      "eval_samples_per_second": 2.489,
      "eval_steps_per_second": 0.664,
      "step": 1
    },
    {
      "epoch": 0.13986013986013987,
      "grad_norm": 0.5461289882659912,
      "learning_rate": 0.0002,
      "loss": 0.2705,
      "step": 10
    },
    {
      "epoch": 0.13986013986013987,
      "eval_loss": 0.17766617238521576,
      "eval_runtime": 12.8826,
      "eval_samples_per_second": 2.329,
      "eval_steps_per_second": 0.621,
      "step": 10
    },
    {
      "epoch": 0.27972027972027974,
      "grad_norm": 0.34120771288871765,
      "learning_rate": 0.00019958568425315314,
      "loss": 0.1263,
      "step": 20
    },
    {
      "epoch": 0.27972027972027974,
      "eval_loss": 0.009738137014210224,
      "eval_runtime": 15.0468,
      "eval_samples_per_second": 1.994,
      "eval_steps_per_second": 0.532,
      "step": 20
    },
    {
      "epoch": 0.4195804195804196,
      "grad_norm": 0.08847692608833313,
      "learning_rate": 0.0001983461701633742,
      "loss": 0.0092,
      "step": 30
    },
    {
      "epoch": 0.4195804195804196,
      "eval_loss": 0.023418640717864037,
      "eval_runtime": 15.0139,
      "eval_samples_per_second": 1.998,
      "eval_steps_per_second": 0.533,
      "step": 30
    },
    {
      "epoch": 0.5594405594405595,
      "grad_norm": 0.10549046844244003,
      "learning_rate": 0.00019629172873477995,
      "loss": 0.0147,
      "step": 40
    },
    {
      "epoch": 0.5594405594405595,
      "eval_loss": 0.013278442434966564,
      "eval_runtime": 12.5204,
      "eval_samples_per_second": 2.396,
      "eval_steps_per_second": 0.639,
      "step": 40
    },
    {
      "epoch": 0.6993006993006993,
      "grad_norm": 0.1356460005044937,
      "learning_rate": 0.00019343938371606712,
      "loss": 0.0018,
      "step": 50
    },
    {
      "epoch": 0.6993006993006993,
      "eval_loss": 0.04859892651438713,
      "eval_runtime": 14.7332,
      "eval_samples_per_second": 2.036,
      "eval_steps_per_second": 0.543,
      "step": 50
    }
  ],
  "logging_steps": 10,
  "max_steps": 355,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 50,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 5,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 3
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3257835454464000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
